{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"~/Projects/AL_HTML/examples/FracPreBake/FractionArithmetic/converted_control.txt\"\n",
    "#path = \"/home/danny/Downloads/ds649_tx_n_4299_2018_0418_004541.txt\"\n",
    "#df = pandas.read_csv(path, sep='\\t', lineterminator='\\n', skip_blank_lines=True).replace({r'\\r': ''}, regex=True)\n",
    "#df = df.rename(index=str, columns={a:a.rstrip() for a in df.keys()})\n",
    "##print(df)\n",
    "#print(\"-----------------\")\n",
    "#path = \"~/Projects/AL_HTML/examples/FracPreBake/FractionArithmetic/converted_human.txt\"\n",
    "#df_human = pandas.read_csv(path, sep='\\t', lineterminator='\\n', skip_blank_lines=True).replace({r'\\r': ''}, regex=True)\n",
    "#df_human = df_human.rename(index=str, columns={a:a.rstrip() for a in df.keys()})\n",
    "#print(df_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student_tables = []\n",
    "#for x in df['Anon Student Id'].unique():\n",
    "#    student_tables.append(df[df['Anon Student Id'] == x])\n",
    "#print([x.shape for x in student_tables])\n",
    "#student_tables_human = []\n",
    "#for x in df_human['Anon Student Id'].unique():\n",
    "#    student_tables_human.append(df_human[df_human['Anon Student Id'] == x])\n",
    "#print([x.shape for x in student_tables_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(t.keys())\n",
    "import copy\n",
    "from pprint import pprint\n",
    "def generate_step_slices(x, KC='KC (Field)'):\n",
    "    outcomes = x['Outcome']\n",
    "    selections = x[KC]\n",
    "    d = {}\n",
    "    #last_correct = 0\n",
    "    for row in range(x.shape[0]):\n",
    "        selection = str(selections[row])\n",
    "        if(selection == \"\"):\n",
    "            continue\n",
    "        l = d.get(selection,[])   \n",
    "        d[selection] = l + [x.iloc[row]]\n",
    "        \n",
    "        if(str(outcomes[row]).strip().upper() == \"CORRECT\"):\n",
    "            \n",
    "            yield pandas.DataFrame(d[str(selections[row])],columns=x.keys())\n",
    "            del d[str(selections[row])]\n",
    "            #yield x[last_correct:row+1]\n",
    "            #last_correct = row+1\n",
    "        \n",
    "            \n",
    "\n",
    "            \n",
    "WRONG_SELECTION =\"Instead of the step you are working on, please work on the highlighted step.\"\n",
    "NOT_DONE = \"I'm sorry, but you are not done yet. Please continue working.\"\n",
    "def generate_step_dicts(student_table, KC='KC (Field)',only_first_error=True):\n",
    "    opportunity_counts = {}\n",
    "    for step_slice in generate_step_slices(student_table):\n",
    "        \n",
    "        #print(step_slice[[\"Selection\",'Input','Outcome']])\n",
    "        #print(\"-------------------------------\")\n",
    "        correct_selection = step_slice['Selection'].iloc[-1]\n",
    "        correct_input = step_slice['Input'].iloc[-1]\n",
    "        step_name = step_slice[KC].iloc[-1]\n",
    "        if(not isinstance(step_name,str) or step_name == \"\"):\n",
    "            continue\n",
    "        \n",
    "        d = {}\n",
    "        for _,table_row in step_slice.iterrows():\n",
    "            #print(\"\\n\")\n",
    "            #print(table_row)\n",
    "            if(str(table_row['Outcome']).strip().upper() == \"INCORRECT\"):\n",
    "                #print(table_row['Selection'], table_row['Action'], table_row['Input'])\n",
    "                \n",
    "                #if(table_row['Selection'] != correct_selection):\n",
    "                if(table_row[\"Feedback Text\"] == WRONG_SELECTION or table_row[\"Feedback Text\"] == NOT_DONE):\n",
    "                    d[\"selection_error\"] = True\n",
    "                elif(table_row['Input'] != correct_input):\n",
    "                    d[\"input_error\"] = True\n",
    "            elif(str(table_row['Outcome']).strip().upper() == \"HINT\"):\n",
    "                d[\"hint\"] = True\n",
    "            if(only_first_error):\n",
    "                break\n",
    "        d['KC'] = step_name \n",
    "        \n",
    "        opportunity_counts[step_name] = opportunity_counts.get(step_name,0) + 1\n",
    "        d['Opportunity'] = opportunity_counts[step_name]\n",
    "        \n",
    "        yield d\n",
    "        #print(\"CORRECT\", correct_selection,step_slice['Action'].iloc[-1], correct_input)\n",
    "        #print(d)\n",
    "        #print(\"\\n\")\n",
    "        \n",
    "def increment_at_index(l,i,amount=0):\n",
    "    if(i < len(l)):\n",
    "        l[i] += amount\n",
    "    elif(i == len(l)):\n",
    "        l.extend([amount])\n",
    "    else:\n",
    "        raise ValueError(\"Nope\", len(l), i)\n",
    "        \n",
    "                \n",
    "def get_learning_curves(student_tables, KC='KC (Field)',only_first_error=True):\n",
    "    kc_dict = {}\n",
    "    kc_template = {\"Counts\": [], \"Errors\": [], \"Selection Errors\": [], \"Input Errors\": [], \"Hint Errors\" : []}\n",
    "    \n",
    "    \n",
    "    for st in student_tables:\n",
    "        for sd in generate_step_dicts(st, KC=KC,only_first_error=only_first_error):\n",
    "            kc_name = sd.get('KC',None)\n",
    "            kc_data = kc_dict.get(kc_name, copy.deepcopy(kc_template))\n",
    "            \n",
    "            \n",
    "            \n",
    "            increment_at_index(kc_data[\"Counts\"], sd[\"Opportunity\"] -1, 1)\n",
    "            \n",
    "            se,ie, h = sd.get('selection_error',False), sd.get('input_error',False),sd.get('hint',False)\n",
    "            op = sd[\"Opportunity\"]\n",
    "            indx = op-1\n",
    "            #print(indx, sd)\n",
    "            #print(kc_name, indx, kc_data)\n",
    "            \n",
    "            \n",
    "            increment_at_index(kc_data[\"Errors\"], indx, 1 if se or ie or h else 0)\n",
    "            \n",
    "            increment_at_index(kc_data[\"Selection Errors\"], indx, 1 if se else 0)\n",
    "            \n",
    "            increment_at_index(kc_data[\"Input Errors\"], indx, 1 if ie else 0)\n",
    "            \n",
    "            increment_at_index(kc_data[\"Hint Errors\"], indx, 1 if h else 0)\n",
    "            \n",
    "            kc_dict[kc_name] = kc_data\n",
    "                    \n",
    "    return kc_dict\n",
    "\n",
    "def gen_student_tables(df):\n",
    "    student_tables = []\n",
    "    for x in df['Anon Student Id'].unique():\n",
    "        student_tables.append(df[df['Anon Student Id'] == x])\n",
    "    return student_tables\n",
    "\n",
    "def transaction_file_to_df(path):\n",
    "    df = pandas.read_csv(path, sep='\\t', lineterminator='\\n', skip_blank_lines=True).replace({r'\\r': ''}, regex=True)\n",
    "    df = df.rename(index=str, columns={a:a.rstrip() for a in df.keys()})\n",
    "    return df\n",
    "            \n",
    "def curves_from_transaction_file(df, KC='KC (Field)',only_first_error=True):\n",
    "    if(not isinstance(df, pandas.DataFrame)):\n",
    "        if(isinstance(df, str)):\n",
    "            #path = \"/home/danny/Downloads/ds649_tx_n_4299_2018_0418_004541.txt\"\n",
    "            df = transaction_file_to_df(df)\n",
    "        else:\n",
    "            raise ValueError(\"Transaction file must be path or pandas.DataFrame, got %s\" % type(df))\n",
    "        \n",
    "        \n",
    "    student_tables = gen_student_tables(df)\n",
    "    learning_curves_by_kc = get_learning_curves(student_tables, KC=KC,only_first_error=only_first_error)\n",
    "    return learning_curves_by_kc\n",
    "    \n",
    "\n",
    "                \n",
    "        #print(step_slice['Selection'])\n",
    "\n",
    "        #print(correct_selection, correct_input)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = student_tables[0]\n",
    "#learning_curves_by_kc = get_learning_curves(student_tables)\n",
    "\n",
    "path = \"human_converted_v2.txt\"\n",
    "human_curves = curves_from_transaction_file(path)\n",
    "del human_curves[\"AS check_convert\"]\n",
    "del human_curves[\"M check_convert\"]\n",
    "\n",
    "path = \"converted_control_id_fix_time_fix.txt\"\n",
    "control_curves = curves_from_transaction_file(path)\n",
    "#pprint(learning_curves_by_kc,width=200)\n",
    "#print(\"--------\")\n",
    "\n",
    "\n",
    "path = \"converted_pretest_time_fix.txt\"\n",
    "pretest_curves = curves_from_transaction_file(path)\n",
    "\n",
    "path = \"substep_converted_v3_id_fix_time_fix.txt\"\n",
    "substep_curves = curves_from_transaction_file(path)\n",
    "\n",
    "path = \"iso_converted_v4_id_fix_time_fix.txt\"\n",
    "iso_curves = curves_from_transaction_file(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"refactorControl_converted_v2_id_fix_time_fix.txt\"\n",
    "refactor_curves = curves_from_transaction_file(path)\n",
    "#pprint(learning_curves_by_kc_human,width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"light_refactor_control_converted_id_fix_time_fix.txt\"\n",
    "light_refactor_curves = curves_from_transaction_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"reintro_bug_control_converted.txt\"\n",
    "reintro_bug_curves = curves_from_transaction_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"final_test_converted.txt\"\n",
    "final_curves = curves_from_transaction_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "def graph_split(name, kc,count_thresh=10,ax=None,show=True,ylim=[-0.01,1.025]):\n",
    "    colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "    \n",
    "    counts = np.array(kc['Counts'], dtype=np.float)\n",
    "    error = np.array(kc['Errors'], dtype=np.float)/counts\n",
    "    s_error = np.array(kc['Selection Errors'], dtype=np.float)/counts\n",
    "    i_error = np.array(kc['Input Errors'], dtype=np.float)/counts\n",
    "    h_error = np.array(kc['Hint Errors'], dtype=np.float)/counts\n",
    "    \n",
    "    print(counts)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if(not ax): ax = plt.subplot(111) \n",
    "    \n",
    "    \n",
    "    x = np.arange(len(counts))+1\n",
    "    \n",
    "    ax.plot(x, error  , marker=\"o\" ,label='total error', color=colors['firebrick'])\n",
    "    ax.plot(x, s_error, marker=\"d\" ,label='selection error', color=colors['gold'])\n",
    "    ax.plot(x, i_error, marker=\"s\" , label='input error', color=colors['seagreen'])\n",
    "    ax.plot(x, h_error, marker=\"1\" ,label='hint error', color=colors['dodgerblue'])\n",
    "    \n",
    "    ax.set_ylim([-0.01,.4])\n",
    "    #ax.set_ylim([-0.01,1.025])\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.minorticks_on()\n",
    "    ax.grid(alpha=.5,which='major')\n",
    "    #ax.grid(alpha=.2,which='minor')\n",
    "    \n",
    "    plt.title(name)\n",
    "    plt.ylabel('Average Error')\n",
    "    plt.xlabel('opportunity')\n",
    "    if(show): plt.show()\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "\n",
    "def graph_kcs(name, kcs,count_thresh=10):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)    \n",
    "    \n",
    "    colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "    l_colors = ['firebrick', 'gold' ,'seagreen', 'dodgerblue', 'darkorchid']\n",
    "    l_markers = ['o', 'd', 's', '|', 'P']\n",
    "    \n",
    "    for i, (kc_name, kc) in enumerate(kcs.items()):\n",
    "        kc = apply_threshold(kc, count_thresh)\n",
    "        \n",
    "        counts = np.array(kc['Counts'], dtype=np.float)\n",
    "        error = np.array(kc['Errors'], dtype=np.float)/counts\n",
    "        x = np.arange(len(counts))+1\n",
    "        \n",
    "        ax.plot(x, error  , marker=l_markers[i] ,label=kc_name, color=colors[l_colors[i]])\n",
    "              \n",
    "    ax.set_ylim([-0.01,1.025])\n",
    "    #ax.set_ylim([-0.01,22])\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.minorticks_on()\n",
    "    ax.grid(alpha=.5,which='major')\n",
    "    ax.grid(alpha=.2,which='minor')\n",
    "    \n",
    "    \n",
    "    if(name != None): plt.title(name)\n",
    "    plt.ylabel('Average Error')\n",
    "    plt.xlabel('opportunity')\n",
    "    plt.show()\n",
    "    \n",
    "def apply_threshold(kc,count_thresh):\n",
    "    counts = np.array(kc['Counts'], dtype=np.float)\n",
    "    l = len(counts)\n",
    "    if(count_thresh > 0):\n",
    "        indx = list(np.nonzero(counts < count_thresh)[0])\n",
    "        if(len(indx) > 0): l = int(indx[0])\n",
    "    new_kc = {}\n",
    "    new_kc['Counts'] = kc['Counts'][:l]\n",
    "    new_kc['Errors'] = kc['Errors'][:l]\n",
    "    new_kc['Selection Errors'] = kc['Selection Errors'][:l]\n",
    "    new_kc['Input Errors'] = kc['Input Errors'][:l]\n",
    "    new_kc['Hint Errors'] = kc['Hint Errors'][:l]\n",
    "    return new_kc\n",
    "    \n",
    "#marker=\"+\"\n",
    "def add_counts(a,b):\n",
    "    if len(a) < len(b):\n",
    "        c = b.copy()\n",
    "        c[:len(a)] += a\n",
    "    else:\n",
    "        c = a.copy()\n",
    "        c[:len(b)] += b\n",
    "    return c\n",
    "def aggregate_curves(d, selection=None):\n",
    "    if(selection == None): selection = d.keys();\n",
    "    print(selection)\n",
    "    agg_curve = {}\n",
    "    for (kc_name, kc) in d.items() :\n",
    "        if(kc_name in selection):\n",
    "            assert 'Counts' in kc and 'Errors' in kc and 'Selection Errors' in kc and 'Input Errors' in kc and 'Hint Errors' in kc, \"bad keys %s:%s\" % (kc_name, str(kc.keys()))\n",
    "            counts = np.array(kc['Counts'], dtype=np.float)\n",
    "            errors = np.array(kc['Errors'], dtype=np.float)\n",
    "            s_errors = np.array(kc['Selection Errors'], dtype=np.float)\n",
    "            i_errors = np.array(kc['Input Errors'], dtype=np.float)\n",
    "            h_errors = np.array(kc['Hint Errors'], dtype=np.float)\n",
    "            agg_curve['Counts'] = add_counts(agg_curve.get('Counts',np.zeros(0)), counts)\n",
    "            agg_curve['Errors'] = add_counts(agg_curve.get('Errors',np.zeros(0)), errors)\n",
    "            agg_curve['Selection Errors'] = add_counts(agg_curve.get('Selection Errors',np.zeros(0)), s_errors)\n",
    "            agg_curve['Input Errors'] = add_counts(agg_curve.get('Input Errors',np.zeros(0)), i_errors)\n",
    "            agg_curve['Hint Errors'] = add_counts(agg_curve.get('Hint Errors',np.zeros(0)), h_errors)\n",
    "    return agg_curve\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_kcs(None, {\"Control\":aggregate_curves(control_curves), \"Refactored\": aggregate_curves(refactor_curves), 'light_refactor': aggregate_curves(light_refactor_curves), \"final\": aggregate_curves(final_curves)})\n",
    "for ((kc_name, control),(_, refactor),(_, light),(_, final)) in zip(control_curves.items(),refactor_curves.items(),light_refactor_curves.items(),final_curves.items()):\n",
    "    graph_kcs(kc_name,{'control': control, \"refactor\":refactor, \"light\":light, \"final\":final}) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(human_curves.keys())\n",
    "graph_kcs(None, {\"No Pretraining\":aggregate_curves(control_curves),\"Estimated Whole Number\":aggregate_curves(substep_curves),\"Demonstrated Pretest\":aggregate_curves(pretest_curves), \"Estimated Fraction\":aggregate_curves(iso_curves), \"Human\":aggregate_curves(human_curves),})\n",
    "\n",
    "\n",
    "graph_split(\"All Knowledge Components -- No Pretraining\", aggregate_curves(control_curves))\n",
    "#for (kc_name, kc) in control_curves.items() :\n",
    "#    graph_split(kc_name, kc)\n",
    "#print(\"----------------------------\")\n",
    "#print(aggregate_curves(human_curves))\n",
    "graph_split(\"All Knowledge Components -- Estimated Whole Number\", aggregate_curves(substep_curves))\n",
    "graph_split(\"All Knowledge Components -- Demonstrated Pretest\", aggregate_curves(pretest_curves))\n",
    "graph_split(\"All Knowledge Components -- Estimated Fraction\", aggregate_curves(iso_curves))\n",
    "#for (kc_name, kc) in iso_curves.items():\n",
    "#    graph_split(kc_name, kc) \n",
    "\n",
    "graph_split(\"All Knowledge Components -- Human\", aggregate_curves(human_curves))\n",
    "\n",
    "\n",
    "graph_kcs(\"All Knowledge Components\", {\"All Knowledge Components -- Estimated Fraction\":aggregate_curves(iso_curves), \"All Knowledge Components -- Human\":aggregate_curves(human_curves),})\n",
    "for ((kc_name, kc),(kc_name_human, kc_human)) in zip(iso_curves.items(),human_curves.items()):\n",
    "    graph_kcs(kc_name,{'human': kc_human, \"iso\":kc}) \n",
    "    print(kc_human['Counts'])\n",
    "    print(kc['Counts'])\n",
    "    \n",
    "    \n",
    "#graph_kcs(\"All KCs\", {\"All KCs -- iso\":aggregate_curves(iso_curves), \"All KCs -- control\":aggregate_curves(control_curves),})\n",
    "#for ((kc_name, kc),(kc_name_human, kc_human)) in zip(iso_curves.items(),control_curves.items()):\n",
    "#    graph_kcs(kc_name,{'control': kc_human, \"iso\":kc}) \n",
    "#    print(kc_human['Counts'])\n",
    "#    print(kc['Counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "np.median\n",
    "for ((kc_name, kc),(kc_name_human, kc_human)) in zip(control_curves.items(),human_curves.items()):\n",
    "    counts = np.array(kc_human['Counts'], dtype=np.float)\n",
    "    human_error = np.array(kc_human['Errors'], dtype=np.float)/counts\n",
    "    \n",
    "    counts = np.array(kc['Counts'], dtype=np.float)\n",
    "    control_error = np.array(kc['Errors'], dtype=np.float)/counts\n",
    "    \n",
    "    inv = list(control_error < human_error[0])\n",
    "    \n",
    "    first = list(inv).index(True) if True in inv else len(counts)\n",
    "    \n",
    "    l = d.get(kc_name.split()[0],[])\n",
    "    l.append(first)\n",
    "    d[kc_name.split()[0]] = l\n",
    "    \n",
    "print(d)\n",
    "print(\"AS-average:\",sum(d['AS'])/float(len(d['AS'])))\n",
    "print(\"AD-average:\",sum(d['AD'])/float(len(d['AD'])))\n",
    "print(\"M-average:\",sum(d['M'])/float(len(d['M'])))\n",
    "print(\"AS-median:\",np.median(d['AS']))\n",
    "print(\"AD-median:\",np.median(d['AD']))\n",
    "print(\"M-median:\",np.median(d['M']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
